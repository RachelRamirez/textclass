getwd()
setwd("./textclass")
setwd("C:/Users/Charter/Desktop/williamcsevier/github/textclass")
document()
install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
getwd()
document()
setwd("..")
getwd()
install("textclass")
install_github('textclass', 'williamcsevier')
install_github('textclass', 'williamcsevier/textclass')
install.packages("shiny")
library(shiny)
runExample("01_hello")
?sliderinput
?sliderInput
shiny::runApp('topic_models')
runApp('topic_models')
install.packages("shinythemes")
shiny::runApp('topic_models')
runApp('topic_models')
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("slam")
install.packages("tm")
shiny::runApp('topic_models')
library(tm)
runApp('topic_models')
?ggplot
install.packages(tidyverse)
install.packages("tidyverse")
?ggplot
?ggplot2
library(tidyverse)
shiny::runApp('topic_models')
shiny::runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
install.packages("topicmodels")
runApp('topic_models')
library(topicmodels)
runApp('topic_models')
runApp('topic_models')
?lda
?topicmodels
library(topicmodels)
?lda
?LDA
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
library(textclass)
runApp('topic_models')
dtm <- tidyDTM(ITdata, 0.98)
dtm <- tidyDTM(ITdata, 0.98)
rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document
dtm <- dtm[rowTotals> 0, ]           #remove all docs without words
lda <- LDA(dtm, 2)
plt <- plot_topics(lda)
plt
return(plt)
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
setwd("C:/Users/Charter/Desktop/williamcsevier/github/textclass/topic_models")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("C:/Users/Charter/Desktop/williamcsevier/github/textclass")
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
data <- ITdata
#how many of each PSC
sw <- add_row(stop_words, word = c("igf","ot", "ct"), lexicon = c("SMART", "SMART", "SMART"))
data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE) %>%
ungroup() %>%
ggplot(aes(word, n)) +
geom_bar()
data <- ITdata
#how many of each PSC
sw <- add_row(stop_words, word = c("igf","ot", "ct"), lexicon = c("SMART", "SMART", "SMART"))
data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE) %>%
ungroup() %>%
ggplot(aes(word, n)) +
geom_bar(stat = "identity")
plt <- data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE)
ITdata <- readRDS("IT_total.RDS")
setwd("C:/Users/Charter/Desktop/williamcsevier/github/textclass/topic_models")
ITdata <- readRDS("IT_total.RDS")
data <- ITdata
#how many of each PSC
sw <- add_row(stop_words, word = c("igf","ot", "ct"), lexicon = c("SMART", "SMART", "SMART"))
plt <- data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE)
ggplot(plt, aes(word, n)) +
geom_bar(stat = "identity")
library(dplyr)
library(ggplot2)
library(tidytext)
library(tm)
data <- ITdata
#how many of each PSC
sw <- add_row(stop_words, word = c("igf","ot", "ct"), lexicon = c("SMART", "SMART", "SMART"))
plt <- data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE)
ggplot(plt, aes(word, n)) +
geom_bar(stat = "identity")
plt <- data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE) %>%
top_n(10,n)
ggplot(plt, aes(word, n)) +
geom_bar(stat = "identity")
ggplot(plt, aes(word, sort(n))) +
geom_bar(stat = "identity")
ggplot(plt, aes(word, sort(n))) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(word, order(n))) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(word, desc(n))) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(word, -n)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(word, n)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(reorder(word, -n), n)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(reorder(word, n), n)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(plt, aes(reorder(word, n), n)) +
geom_bar(stat = "identity") +
xlab("Term") +
ylab("Count") +
coord_flip()
shiny::runApp()
runApp()
library(textclass)
setwd("C:/Users/Charter/Desktop/williamcsevier/github/textclass")
library(textclass)
runApp('topic_models')
library(textclass)
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
library(textclass)
runApp('topic_models')
sw <- add_row(stop_words, word = c("igf","ot", "ct"), lexicon = c("SMART", "SMART", "SMART"))
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = n) %>%
anti_join(sw) %>%
count( word, sort = TRUE) %>%
top_n(10,n)
library(textclass)
runApp('topic_models')
runApp('topic_models')
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = 2) %>%
anti_join(sw) %>%
count( word, sort = TRUE) %>%
top_n(10,n)
plt
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = 3) %>%
separate(word, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
unite("word", c(word1, word2,word3) sep ="") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = 3) %>%
separate(word, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
unite("word", c(word1, word2,word3), sep ="") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
plt
library(textclass)
runApp('topic_models')
plt
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = 4) %>%
separate(word, c("word1", "word2", "word3", "word4"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
filter(!word4 %in% sw$word) %>%
unite("word", c(word1, word2, word3, word4), sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
plt
library(textclass)
runApp('topic_models')
runApp('topic_models')
ggplot(plt, aes(reorder(word, n), n)) +
geom_bar(stat = "identity") +
xlab("Term") +
ylab("Count") +
coord_flip()
library(textclass)
runApp('topic_models')
data %>%
unnest_tokens(word, description, token = "ngrams", n = n) %>%
separate(word, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
unite("word", c(word1, word2, word3), sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
data %>%
unnest_tokens(word, description, token = "ngrams", n = 3) %>%
separate(word, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
unite("word", c(word1, word2, word3), sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
data %>%
unnest_tokens(word, description, token = "ngrams", n = n) %>%
separate(word, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
unite("word", word1, word2, sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
data %>%
unnest_tokens(word, description, token = "ngrams", n = 2) %>%
separate(word, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
unite("word", word1, word2, sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
term_frequency <- function(data,n){
sw <- add_row(stop_words, word = c("igf","ot", "ct"), lexicon = c("SMART", "SMART", "SMART"))
if(n == 2){
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = n) %>%
separate(word, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
unite("word", word1, word2, sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
}
else if(n==3){
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = n) %>%
separate(word, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
unite("word", c(word1, word2, word3), sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
}
else if(n==4){
plt <- data %>%
unnest_tokens(word, description, token = "ngrams", n = n) %>%
separate(word, c("word1", "word2", "word3", "word4"), sep = " ") %>%
filter(!word1 %in% sw$word) %>%
filter(!word2 %in% sw$word) %>%
filter(!word3 %in% sw$word) %>%
filter(!word4 %in% sw$word) %>%
unite("word", c(word1, word2, word3, word4), sep =" ") %>%
count( word, sort = TRUE) %>%
top_n(10,n)
}
else if(n>4){
print("too many n-grams")
}
else{
plt <- data %>%
unnest_tokens(word, description) %>%
anti_join(sw) %>%
count( word, sort = TRUE) %>%
top_n(10,n)}
plt <- ggplot(plt, aes(reorder(word, n), n)) +
geom_bar(stat = "identity") +
xlab("Term") +
ylab("Count") +
coord_flip()
return(plt)
}
term_frequency(data,1)
term_frequency(data,2)
term_frequency(data,3)
library(textclass)
runApp('topic_models')
runApp('topic_models')
install.packages(ldatuning)
install.packages("ldatuning")
library(textclass)
library(textclass)
library(textclass)
library(roxygen2)
library(textclass)
library(textclass)
devtools::check(textclass)
devtools::check("textclass")
setwd("C:/Users/Charter/Desktop/williamcsevier/github")
devtools::check("textclass")
library(textclass)
?term_frequency()
library(textclass)
setwd("C:/Users/Charter/Desktop/williamcsevier/github/textclass")
data <- readRDS("ITdata.RDS")
data <- readRDS("topic_models\ITdata.RDS")
data <- readRDS("topic_models/ITdata.RDS")
data <- readRDS("./topic_models/ITdata.RDS")
data <- readRDS("./topic_models/IT_total.RDS")
AFICAdata <- data
devtools::use_data(AFICAdata)
devtools::document()
devtools::document()
devtools::load_all
devtools::load_all()
?AFICAdata
str(AFICAdata)
devtools::document()
devtools::load_all()
devtools::document()
devtools::load_all()
?AFICAdata
devtools::document()
devtools::load_all()
?AFICAdata
devtools::use_testthat
devtools::use_testthat()
library(textclass)
?term_frequency
.GlobalEnv
View(term_frequency)
unloadNamespace("term_frequency")
rm(term_frequency)
library(textclass)
devtools::use_vignette("textclass")
runApp('topic_models')
install.packages("shinyjs")
shiny::runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
runApp('topic_models')
library(textclass)
library(textclass)
runApp()
library(textclass)
runApp()
library(textclass)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
vignette(textclass)
vignette()
vignette("textclass")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?stringr
vignette(package = "tidyverse")
vignette(package = "tidytext")
??Stringr
install.packages("ggraph")
runApp()
install.packages("tweenr")
runApp()
runApp()
install.packages("igraph")
runApp()
runApp()
runApp()
?igraph
install.packages("igraph")
runApp()
install.packages("igraph", force = TRUE)
install.packages("igraph", dependencies = TRUE)
runApp()
.libPaths()
library("igraph")
